{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Train MoCo on CIFAR-10\n",
    "\n",
    "Main Reference:\n",
    "\n",
    "[Tutorial 2: Train MoCo on CIFAR-10](https://docs.lightly.ai/self-supervised-learning/tutorials/package/tutorial_moco_memory_bank.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training self-supervised models using contrastive loss we usually face one big problem. To get good results, we need many negative examples for the contrastive loss to work. Therefore, we need a large batch size. However, not everyone has access to a cluster full of GPUs or TPUs. To solve this problem, alternative approaches have been developed. Some of them use a memory bank to store old negative examples we can query to compensate for the smaller batch size. MoCo takes this approach one step further by including a momentum encoder."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the CIFAR-10 dataset for this tutorial."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from lightly.data import LightlyDataset\n",
    "from lightly.loss import NTXentLoss\n",
    "from lightly.models.modules.heads import MoCoProjectionHead\n",
    "from lightly.models.utils import (\n",
    "    batch_shuffle,\n",
    "    batch_unshuffle,\n",
    "    deactivate_requires_grad,\n",
    "    update_momentum,\n",
    ")\n",
    "from lightly.transforms import MoCoV2Transform, utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default configuration uses a batch size of 512. This requires around 6.4GB of GPU memory. When training for 100 epochs you should achieve around 73% test set accuracy. When training for 200 epochs accuracy increases to about 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8\n",
    "batch_size = 256\n",
    "memory_bank_size = 1024\n",
    "seed = 1\n",
    "max_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset structure should be like this:\n",
    "# cifar10/train/\n",
    "#  L airplane/\n",
    "#    L 10008_airplane.png\n",
    "#    L ...\n",
    "#  L automobile/\n",
    "#  L bird/\n",
    "#  L cat/\n",
    "#  L deer/\n",
    "#  L dog/\n",
    "#  L frog/\n",
    "#  L horse/\n",
    "#  L ship/\n",
    "#  L truck/\n",
    "path_to_train = \"/data/cifar-10-kaggle/cifar10/cifar10/train\"\n",
    "path_to_test = \"/data/cifar-10-kaggle/cifar10/cifar10/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup data augmentations and loaders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with our data preprocessing pipeline. We can implement augmentations from the MoCo paper using the transforms provided by lightly. Images from the CIFAR-10 dataset have a resolution of 32x32 pixels. Let’s use this resolution to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable blur because we're working with tiny images\n",
    "moco_transform = MoCoV2Transform(\n",
    "    input_size=32,\n",
    "    gaussian_blur=0.0,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don’t want any augmentation for our test data. Therefore, we create custom, torchvision based data transformations. Let’s ensure the size is correct and we normalize the data in the same way as we do with the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations typically used to train on cifar-10\n",
    "train_classifier_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.RandomCrop(32, padding=4),\n",
    "        torchvision.transforms.RandomHorizontalFlip(),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=utils.IMAGENET_NORMALIZE[\"mean\"],\n",
    "            std=utils.IMAGENET_NORMALIZE[\"std\"],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# No additional augmentations for the test set\n",
    "test_transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize((32, 32)),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=utils.IMAGENET_NORMALIZE[\"mean\"],\n",
    "            std=utils.IMAGENET_NORMALIZE[\"std\"],\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# We use the moco augmentations for training moco\n",
    "dataset_train_moco = LightlyDataset(input_dir=path_to_train, transform=moco_transform)\n",
    "\n",
    "# Since we also train a linear classifier on the pre-trained moco model we\n",
    "# reuse the test augmentations here (MoCo augmentations are very strong and\n",
    "# usually reduce accuracy of models which are not used for contrastive learning.\n",
    "# Our linear layer will be trained using cross entropy loss and labels provided\n",
    "# by the dataset. Therefore we chose light augmentations.)\n",
    "dataset_train_classifier = LightlyDataset(\n",
    "    input_dir=path_to_train, transform=train_classifier_transforms\n",
    ")\n",
    "\n",
    "dataset_test = LightlyDataset(input_dir=path_to_test, transform=test_transforms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataloaders to load and preprocess the data in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train_moco = torch.utils.data.DataLoader(\n",
    "    dataset_train_moco,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "dataloader_train_classifier = torch.utils.data.DataLoader(\n",
    "    dataset_train_classifier,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the MoCo Lightning Module"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create our MoCo model. We use PyTorch Lightning to train our model. We follow the specification of the lightning module. In this example we set the number of features for the hidden dimension to 512. The momentum for the Momentum Encoder is set to 0.99 (default is 0.999) since other reports show that this works better for Cifar-10."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the backbone we use the lightly variant of a Mobilenet-v2. You can use another model following our playground to use custom backbones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MocoModel(pl.LightningModule):\n",
    "    def __init__(self, num_ftrs=512):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_ftrs = num_ftrs\n",
    "\n",
    "        # create a Mobilenet_v2 backbone and remove the classification head\n",
    "        mobilenet_v2 = torchvision.models.mobilenet_v2()\n",
    "        self.backbone = nn.Sequential(\n",
    "            *list(mobilenet_v2.children())[:-1],\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1280, num_ftrs, bias=False)\n",
    "            )\n",
    "\n",
    "        # resnet = ResNetGenerator(\"resnet-18\", 1, num_splits=8)\n",
    "        # self.backbone = nn.Sequential(\n",
    "        #     *list(resnet.children())[:-1],\n",
    "        #     nn.AdaptiveAvgPool2d(1),\n",
    "        # )\n",
    "\n",
    "        # create a moco model based on ResNet\n",
    "        self.projection_head = MoCoProjectionHead(num_ftrs, 512, 128)\n",
    "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
    "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
    "        deactivate_requires_grad(self.backbone_momentum)\n",
    "        deactivate_requires_grad(self.projection_head_momentum)\n",
    "\n",
    "        # create our loss with the optional memory bank\n",
    "        self.criterion = NTXentLoss(temperature=0.1, memory_bank_size=memory_bank_size)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x_q, x_k), _, _ = batch\n",
    "\n",
    "        # update momentum\n",
    "        update_momentum(self.backbone, self.backbone_momentum, 0.99)\n",
    "        update_momentum(self.projection_head, self.projection_head_momentum, 0.99)\n",
    "\n",
    "        # get queries\n",
    "        q = self.backbone(x_q).flatten(start_dim=1)\n",
    "        q = self.projection_head(q)\n",
    "\n",
    "        # get keys\n",
    "        k, shuffle = batch_shuffle(x_k)\n",
    "        k = self.backbone_momentum(k).flatten(start_dim=1)\n",
    "        k = self.projection_head_momentum(k)\n",
    "        k = batch_unshuffle(k, shuffle)\n",
    "\n",
    "        loss = self.criterion(q, k)\n",
    "        self.log(\"train_loss_ssl\", loss)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.custom_histogram_weights()\n",
    "\n",
    "    # We provide a helper method to log weights in tensorboard\n",
    "    # which is useful for debugging.\n",
    "    def custom_histogram_weights(self):\n",
    "        for name, params in self.named_parameters():\n",
    "            self.logger.experiment.add_histogram(name, params, self.current_epoch)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(\n",
    "            self.parameters(),\n",
    "            lr=6e-2,\n",
    "            momentum=0.9,\n",
    "            weight_decay=5e-4,\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
    "        return [optim], [scheduler]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Classifier Lightning Module"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a linear classifier using the features we extract using MoCo and train it on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(pl.LightningModule):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "        # use the pretrained ResNet backbone\n",
    "        self.backbone = backbone\n",
    "\n",
    "        # freeze the backbone\n",
    "        deactivate_requires_grad(backbone)\n",
    "\n",
    "        # create a linear layer for our downstream classification model\n",
    "        self.fc = nn.Linear(512, 10)\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_hat = self.backbone(x).flatten(start_dim=1)\n",
    "        y_hat = self.fc(y_hat)\n",
    "        return y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss_fc\", loss)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.custom_histogram_weights()\n",
    "\n",
    "    # We provide a helper method to log weights in tensorboard\n",
    "    # which is useful for debugging.\n",
    "    def custom_histogram_weights(self):\n",
    "        for name, params in self.named_parameters():\n",
    "            self.logger.experiment.add_histogram(name, params, self.current_epoch)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y, _ = batch\n",
    "        y_hat = self.forward(x)\n",
    "        y_hat = torch.nn.functional.softmax(y_hat, dim=1)\n",
    "\n",
    "        # calculate number of correct predictions\n",
    "        _, predicted = torch.max(y_hat, 1)\n",
    "        num = predicted.shape[0]\n",
    "        correct = (predicted == y).float().sum()\n",
    "        self.validation_step_outputs.append((num, correct))\n",
    "        return num, correct\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # calculate and log top1 accuracy\n",
    "        if self.validation_step_outputs:\n",
    "            total_num = 0\n",
    "            total_correct = 0\n",
    "            for num, correct in self.validation_step_outputs:\n",
    "                total_num += num\n",
    "                total_correct += correct\n",
    "            acc = total_correct / total_num\n",
    "            self.log(\"val_acc\", acc, on_epoch=True, prog_bar=True)\n",
    "            self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optim = torch.optim.SGD(self.fc.parameters(), lr=30.0)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, max_epochs)\n",
    "        return [optim], [scheduler]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the MoCo model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TIP`: Checkout the tensorboard logs while the model is training.\n",
    "\n",
    "tensorboard –logdir lightning_logs/ to start tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can instantiate the model and train it using the lightning trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                     | Type               | Params\n",
      "----------------------------------------------------------------\n",
      "0 | backbone                 | Sequential         | 2.9 M \n",
      "1 | projection_head          | MoCoProjectionHead | 328 K \n",
      "2 | backbone_momentum        | Sequential         | 2.9 M \n",
      "3 | projection_head_momentum | MoCoProjectionHead | 328 K \n",
      "4 | criterion                | NTXentLoss         | 0     \n",
      "----------------------------------------------------------------\n",
      "3.2 M     Trainable params\n",
      "3.2 M     Non-trainable params\n",
      "6.4 M     Total params\n",
      "25.660    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 195/195 [00:28<00:00,  6.76it/s, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 195/195 [00:31<00:00,  6.21it/s, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model = MocoModel()\n",
    "trainer = pl.Trainer(max_epochs=max_epochs,\n",
    "                     devices=1,\n",
    "                     accelerator=\"gpu\",\n",
    "                     precision=16,\n",
    "                     )\n",
    "trainer.fit(model, dataloader_train_moco)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | backbone  | Sequential       | 2.9 M \n",
      "1 | fc        | Linear           | 5.1 K \n",
      "2 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "5.1 K     Trainable params\n",
      "2.9 M     Non-trainable params\n",
      "2.9 M     Total params\n",
      "11.537    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 195/195 [00:09<00:00, 20.21it/s, v_num=2, val_acc=0.149]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 195/195 [00:10<00:00, 17.93it/s, v_num=2, val_acc=0.149]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "classifier = Classifier(model.backbone)\n",
    "trainer = pl.Trainer(max_epochs=max_epochs, devices=1, accelerator=\"gpu\")\n",
    "trainer.fit(classifier, dataloader_train_classifier, dataloader_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
